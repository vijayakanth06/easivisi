# EasiVisi - Visual AI Training Platform ğŸ¯

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-Web%20Framework-green.svg)](https://flask.palletsprojects.com/)
[![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-purple.svg)](https://ultralytics.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **Train custom object detection models without writing a single line of code!**

EasiVisi is a powerful, user-friendly **Flask web application** that enables users to **annotate images**, **train**, and **fine-tune YOLO models** for custom object detection tasks â€” all through an intuitive browser-based interface. No deep learning expertise required!

---

## ğŸŒŸ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ–¼ï¸ **Web-Based Image Annotation** | Draw bounding boxes directly in your browser with an intuitive annotation tool |
| ğŸš€ **One-Click YOLO Training** | Train YOLOv8 models with customizable hyperparameters via simple UI controls |
| ğŸ”§ **Model Fine-Tuning** | Fine-tune pre-trained YOLO models on your custom datasets |
| ğŸ“Š **Real-Time Training Metrics** | Monitor loss, mAP, and other metrics with TensorBoard integration |
| ğŸ’¾ **Dataset Management** | Organize, import, and export datasets in YOLO format |
| ğŸ¯ **Object Detection Inference** | Test trained models on new images instantly |
| ğŸ“± **Responsive Design** | Works seamlessly on desktop and tablet devices |

---

## ğŸ“¸ Screenshots

<details>
<summary><strong>ğŸ–¥ï¸ Dashboard & Dataset Management</strong></summary>
<br>

![Dashboard](static/images/Screenshot%202026-01-01%20221029.png)

</details>

<details>
<summary><strong>âœï¸ Image Annotation Tool</strong></summary>
<br>

![Annotation Tool](static/images/Screenshot%202026-01-01%20221123.png)

</details>

<details>
<summary><strong>ğŸ·ï¸ Class Label Configuration</strong></summary>
<br>

![Class Configuration](static/images/Screenshot%202026-01-01%20221141.png)

</details>

<details>
<summary><strong>âš™ï¸ Training Configuration</strong></summary>
<br>

![Training Setup](static/images/Screenshot%202026-01-01%20221232.png)

</details>

<details>
<summary><strong>ğŸ¯ Object Detection Inference</strong></summary>
<br>

![Inference Results](static/images/Screenshot%202026-01-01%20221311.png)

</details>

---

## ğŸ¯ Use Cases

- **Manufacturing Quality Control** â€” Detect defects, stains, or anomalies in products
- **Retail & Inventory** â€” Count and classify items on shelves
- **Agriculture** â€” Identify crop diseases, pests, or ripe produce
- **Security & Surveillance** â€” Custom object detection for monitoring systems
- **Medical Imaging** â€” Train models for preliminary screening (non-diagnostic)
- **Sports Analytics** â€” Track players, equipment, and movements
- **Wildlife Conservation** â€” Monitor and count animal species

---

## ğŸ› ï¸ Technology Stack

| Category | Technologies |
|----------|-------------|
| **Backend** | Python, Flask |
| **Deep Learning** | PyTorch, Ultralytics YOLOv8 |
| **Image Processing** | OpenCV, Pillow, NumPy |
| **Visualization** | Matplotlib, Seaborn, TensorBoard |
| **Dataset Tools** | PyYAML, Pandas, pycocotools |
| **Frontend** | HTML5, CSS3, JavaScript |

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- (Optional) NVIDIA GPU with CUDA for faster training

### Quick Start

```bash
# Clone the repository
git clone https://github.com/ponaalagar/easivisi.git
cd easivisi

# Create virtual environment (recommended)
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

---

## ğŸš€ Usage

### 1. Start the Web Application

```bash
# Start the Flask server
python app.py
```

Open your browser and navigate to `http://localhost:5000`

### 2. Create a Dataset

Use the web interface to:
1. Go to **Datasets** page
2. Click **Create New Dataset**
3. Upload your images
4. Define class names
5. Annotate images using the built-in annotation tool
6. Split into train/val sets

### 3. Dataset Structure (Reference)

Datasets are automatically organized in the YOLO format:

```
dataset/
â””â”€â”€ your_dataset/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ train/
    â”‚   â””â”€â”€ val/
    â”œâ”€â”€ labels/
    â”‚   â”œâ”€â”€ train/
    â”‚   â””â”€â”€ val/
    â””â”€â”€ dataset.yaml
```

### 4. Train Your Model

Use the **Training** page in the web interface to:
- Select your dataset
- Choose a YOLO model variant
- Configure hyperparameters
- Start training with one click

Or train via command line:

```bash
python train.py
```

---

## âš™ï¸ Training Configuration

Customize training parameters in `train.py`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `epochs` | 50 | Number of training epochs |
| `imgsz` | 640 | Input image size |
| `batch` | 16 | Batch size |
| `device` | cpu | Training device (`cpu`, `0`, `0,1` for multi-GPU) |
| `workers` | 4 | Number of data loading workers |
| `pretrained` | True | Use pretrained weights |

### Available YOLO Models

| Model | Size | mAP | Speed |
|-------|------|-----|-------|
| `yolov8n.pt` | Nano | Good | Fastest |
| `yolov8s.pt` | Small | Better | Fast |
| `yolov8m.pt` | Medium | Great | Balanced |
| `yolov8l.pt` | Large | Excellent | Slower |
| `yolov8x.pt` | Extra Large | Best | Slowest |

---

## ğŸ“Š Training Outputs

After training, find your results in:

```
runs/
â””â”€â”€ your_training_run/
    â”œâ”€â”€ weights/
    â”‚   â”œâ”€â”€ best.pt      # Best model weights
    â”‚   â””â”€â”€ last.pt      # Latest model weights
    â”œâ”€â”€ results.csv      # Training metrics
    â”œâ”€â”€ confusion_matrix.png
    â”œâ”€â”€ results.png      # Training curves
    â””â”€â”€ ...
```

### Monitor Training with TensorBoard

```bash
tensorboard --logdir runs
```

---

## ğŸ–¥ï¸ Web Interface Features

### Image Annotation Tool
- **Drag-to-draw** bounding boxes
- **Multi-class labeling** with color coding
- **Keyboard shortcuts** for efficiency
- **Zoom and pan** for precise annotations
- **Undo/Redo** functionality
- **Export to YOLO format** with one click

### Training Dashboard
- **Hyperparameter configuration** via intuitive forms
- **Real-time training progress** visualization
- **Model comparison** tools
- **One-click model export**

### Inference Playground
- **Upload images** for instant detection
- **Confidence threshold** adjustment
- **Batch processing** support
- **Download annotated results**

---

## ğŸ“ Project Structure

```
easivisi/
â”œâ”€â”€ app.py               # Flask web application
â”œâ”€â”€ config.py            # Application configuration
â”œâ”€â”€ train.py             # Model training script
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ README.md            # Project documentation
â”œâ”€â”€ dataset/             # Dataset storage
â”‚   â””â”€â”€ <dataset_name>/
â”‚       â”œâ”€â”€ images/      # Training and validation images
â”‚       â”œâ”€â”€ labels/      # YOLO format annotations
â”‚       â””â”€â”€ dataset.yaml # Dataset configuration
â”œâ”€â”€ models/              # Pre-trained model weights
â”œâ”€â”€ runs/                # Training outputs (generated)
â”œâ”€â”€ uploads/             # Temporary upload storage
â”œâ”€â”€ static/              # Static assets (CSS, JS)
â”œâ”€â”€ templates/           # HTML templates
â”‚   â”œâ”€â”€ index.html       # Home page
â”‚   â”œâ”€â”€ dataset.html     # Dataset management
â”‚   â”œâ”€â”€ annotate.html    # Annotation tool
â”‚   â”œâ”€â”€ train.html       # Training configuration
â”‚   â”œâ”€â”€ inference.html   # Model inference
â”‚   â””â”€â”€ runs.html        # Training history
â””â”€â”€ utils/               # Utility modules
    â”œâ”€â”€ annotation.py    # Annotation helpers
    â”œâ”€â”€ dataset.py       # Dataset management
    â”œâ”€â”€ training.py      # Training pipeline
    â””â”€â”€ inference.py     # Inference helpers
```

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

### Development Setup

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/

# Run linting
flake8 .
```

---

## ğŸ“ Roadmap

- [x] YOLOv8 training integration
- [x] Flask web interface for annotation
- [x] Real-time training visualization
- [ ] Model export to ONNX, TensorRT
- [ ] Docker containerization
- [ ] REST API for inference
- [ ] Multi-user support with authentication
- [ ] Cloud deployment guides (AWS, GCP, Azure)

---

## ğŸ› Troubleshooting

### Common Issues

<details>
<summary><strong>CUDA out of memory</strong></summary>

Reduce batch size or image size:
```python
model.train(batch=8, imgsz=416)
```
</details>

<details>
<summary><strong>Training is slow on CPU</strong></summary>

For GPU acceleration, install CUDA-enabled PyTorch:
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```
</details>

<details>
<summary><strong>Dataset not found error</strong></summary>

Ensure paths in `dataset.yaml` are correct and relative to the project root.
</details>

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Ultralytics](https://ultralytics.com/) for the amazing YOLOv8 framework
- [Flask](https://flask.palletsprojects.com/) for the lightweight web framework
- [PyTorch](https://pytorch.org/) for the deep learning backend

---

## ğŸ“§ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/ponaalagar/easivisi/issues)
- **Discussions**: [GitHub Discussions](https://github.com/ponaalagar/easivisi/discussions)
- **Email**: ponaalagarok@gmail.com

---

<div align="center">

### â­ Star this repo if you find it helpful!

**Made with â¤ï¸ for the Computer Vision Community**

[Report Bug](https://github.com/ponaalagar/easivisi/issues) Â· [Request Feature](https://github.com/ponaalagar/easivisi/issues)

</div>

---

## ğŸ”‘ Keywords

`yolo` `object-detection` `image-annotation` `flask` `machine-learning` `deep-learning` `computer-vision` `pytorch` `yolov8` `training-pipeline` `annotation-tool` `no-code-ml` `defect-detection` `custom-object-detection` `ai-training` `visual-inspection`
